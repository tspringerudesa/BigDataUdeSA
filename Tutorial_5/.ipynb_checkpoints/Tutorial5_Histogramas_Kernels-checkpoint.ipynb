{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObeIwb_npgeZ"
   },
   "source": [
    "# Tutorial de Big Data (UdeSA) 2025\n",
    "## Tutorial 5\n",
    "\n",
    "### M√©todos no param√©tricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M√©todos no param√©tricos\n",
    "El objetivo es predecir distribuci√≥n de una variable de inter√©s \n",
    "- ùëå variable de inter√©s\n",
    "- ùëì(ùëå) distribuci√≥n de ùëå\n",
    "\n",
    "M√©todos\n",
    "- Introducci√≥n a Numpy y Scikit-learn \n",
    "- Histogramas\n",
    "- Kernels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy y scikit-learn\n",
    "**El paquete NumPy** es fundamental en Python. Est√° escrito en lenguajes de bajo nivel, lo que permite realizar operaciones matem√°ticas de manera muy eficiente. Para m√°s informaci√≥n, ver la [gu√≠a oficial de uso de NumPy](https://docs.scipy.org/doc/numpy/user/index.html).\n",
    "\n",
    "**El paquete scikit-learn** es una biblioteca de Python usada para machine learning, construida encima de NumPy y otros paquetes. Permite procesar datos, reducir la dimensionalidad de la base, implementar regresiones, clasificaciones, clustering y m√°s. Pueden ver la [web de scikit-learn](https://scikit-learn.org/stable/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installamos el paquete necesario\n",
    "#!pip install scikit-learn\n",
    "\n",
    "# Alternativa\n",
    "import sys\n",
    "!{sys.executable} -m pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos paquetes\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy\n",
    "\n",
    "A continuaci√≥n crearemos dos vectores con los que trabajaremos en nuestra primera regresi√≥n lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([5, 15, 25, 35, 45, 55])\n",
    "y = np.array([5, 20, 14, 32, 22, 38])\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "# Ambos son vectores fila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape para transformar x en un vector columna\n",
    "x = x.reshape((-1, 1))   # El -1 indica el largo del array\n",
    "# Es equivalente a: x = x.reshape((6, 1))\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogramas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar hist de Matplotlib. Ver documentaci√≥n [ac√°](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos datos\n",
    "np.random.seed(20)\n",
    "X = np.concatenate([np.random.normal(0,1,500), np.random.normal(5,1,500)]).reshape(-1,1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(X, color='blue', alpha=0.5) # por default, 10 bins\n",
    "plt.xlabel('Valores')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mayor n√∫mero de barras (bins en ingles), menos observaciones se acumulan en cada bin (notar diferencia de escala en el eje y), como muestra el siguiente gr√°fico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(X, bins=30, alpha=0.5, color='blue', label='Histograma')\n",
    "plt.xlabel('Valores')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(X, bins=30, alpha=0.5, color='blue', label='Histograma')\n",
    "plt.xlabel('Valores')\n",
    "plt.ylabel('Frecuencia')\n",
    "\n",
    "# Agregamos l√≠nea vertical con la media\n",
    "mean_value = np.mean(X)\n",
    "plt.axvline(mean_value, color='red', linestyle='dashed', linewidth=1, label='Media')\n",
    "plt.legend()  # Show legend with label for the mean line\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos un criterio para \"cortar\" outliers (por ejemplo, a 2 DE de la media)\n",
    "mean_value = np.mean(X)\n",
    "std_dev = np.std(X)\n",
    "lower_bound = mean_value - 2 * std_dev\n",
    "upper_bound = mean_value + 2 * std_dev\n",
    "\n",
    "# Filtramos los datos\n",
    "X_filtered = X[(X >= lower_bound) & (X <= upper_bound)]\n",
    "\n",
    "# Plot histogram of filtered data\n",
    "plt.hist(X, bins=30, alpha=0.3, color='blue', label='Histograma')\n",
    "plt.hist(X_filtered, bins=30, alpha=0.3, color='orange', label='Histograma')\n",
    "plt.xlabel('Valores')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambi√©n podemos usar algunas funciones de seaborn para graficar histogramas. Ver documentaci√≥n [ac√°](https://seaborn.pydata.org/generated/seaborn.histplot.html#seaborn.histplot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero, installamos el paquete\n",
    "import sys\n",
    "!{sys.executable} -m pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segundo, algunos tal vez necesiten el update\n",
    "pip install -U seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = sns.load_dataset(\"tips\")\n",
    "tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=tips['tip'])\n",
    "mean_tips = np.mean(tips['tip'])\n",
    "plt.axvline(mean_tips, color='red', linestyle='dashed', linewidth=1, label='Mean tips')\n",
    "plt.legend()  # Nos muestra la leyenda para la media de tips\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=tips, x=\"tip\", hue=\"sex\", multiple=\"stack\") #podemos hacer el histograma por grupos: varon, mujer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos sumar la estimaci√≥n de la densidad usando un Kernel (Gaussiano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=tips, x=\"tip\", hue=\"sex\", stat=\"percent\", multiple=\"stack\",  kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel:\n",
    "A cada observaci√≥n le estima una peque√±a funci√≥n de densidad y suma todas las peque√±as funciones\n",
    "\n",
    "$$\n",
    "ùëì(ùë¶_0)= \\frac{1}{n} ‚àë^ùëõ_i  \\frac{1}{h} ùêæ(\\frac{ùëå_ùëñ‚àíùë¶_0}{h}) \n",
    "$$\n",
    "\n",
    "- ùêæ(ùëß)  funci√≥n Kernel continua (y generalmente) sim√©trica \n",
    "- ‚Ñé ancho de banda (smoothing bandwidth) --> Controla qu√© tan ‚Äúsuave‚Äù es la densidad \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a usar el [m√≥dulo neighbors de Scikit learn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KernelDensity.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para estimar una densidad usando kernels tenemos la siguiente funci√≥n: \n",
    "\n",
    "<code> sklearn.neighbors.KernelDensity(*, bandwidth=1.0, algorithm='auto', kernel='gaussian', metric='euclidean', atol=0, rtol=0, breadth_first=True, leaf_size=40, metric_params=None)</code>\n",
    "\n",
    "donde algunos par√°metros importantes son:\n",
    "- <code>bandwidth</code> (valor por default: 1.0)\n",
    "- <code>kernel</code> (valor por default: 'gaussian')\n",
    "\n",
    "Scikit learn nos permite cambiar el kernel y probar varios y cu√°l ajusta mejor a los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero instalamos sklearn (Seguimos las instrucciones de https://github.com/scikit-learn/sklearn-pypi-package)\n",
    "import sys\n",
    "!{sys.executable} -m pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tambien se necesita el siguiente modulo: scipy, base\n",
    "import sys\n",
    "#!{sys.executable} -m pip install scipy\n",
    "#!{sys.executable} -m pip install base\n",
    "#!pip install -U scikit-learn # update del paquete sklearn/scikit-learn\n",
    "!{sys.executable} -m pip install --upgrade pandas\n",
    "!{sys.executable} -m pip install --upgrade numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tipos de kernels (disponibles en Scikit learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernels\n",
    "kernels = [\"gaussian\", \"tophat\", \"epanechnikov\", \"exponential\", \"linear\", \"cosine\"] \n",
    "  \n",
    "# Figura con 3 filas y 2 columnas\n",
    "fig, ax = plt.subplots(3, 2) \n",
    "# Tama√±o de la figura\n",
    "fig.set_figheight(15) \n",
    "fig.set_figwidth(10)   \n",
    "# T√≠tulo \n",
    "fig.suptitle(\"Tipos de kernels\") \n",
    "\n",
    "# 1D array de valores de x para graficar la distribuci√≥n \n",
    "x_plot = np.linspace(-6, 6, 1000) # 1000 valores de -6 a 6 separados con la misma distancia entre s√≠\n",
    "x_plot = x_plot.reshape(-1,1) # formato 2D array (necesario para scikit learn)\n",
    "x_orig = np.zeros((1, 1)) # punto (0,0)\n",
    "  \n",
    "# Graficamos usando los distintos kernels \n",
    "for i, kernel in enumerate(kernels): \n",
    "    # Ajustamos el modelo \n",
    "    kde = KernelDensity(kernel=kernel).fit(x_orig) # usamos el punto (0,0)\n",
    "    # log de la densidad de probabilidad (PDF)\n",
    "    log_dens = kde.score_samples(x_plot) \n",
    "      \n",
    "    # Distribuciones \n",
    "    ax[i // 2, i % 2].fill(x_plot[:, 0], np.exp(log_dens)) \n",
    "    # i//2 nos permite referirnos a la fila del subplot, e i%2 nos permite referirnos a la columna\n",
    "    # T√≠tulo y labels de los subplots \n",
    "    ax[i // 2, i % 2].set_title(kernel.capitalize()) \n",
    "    ax[i // 2, i % 2].set_xlim(-3, 3) \n",
    "    ax[i // 2, i % 2].set_ylim(0, 1) \n",
    "    ax[i // 2, i % 2].set_ylabel(\"Densidad\") \n",
    "    ax[i // 2, i % 2].set_xlabel(\"x\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma forma, en un gr√°fico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernels\n",
    "kernels = [\"gaussian\", \"tophat\", \"epanechnikov\", \"exponential\", \"linear\", \"cosine\"] \n",
    "  \n",
    "# Grafico\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "for k in kernels:\n",
    "    # Ajustamos el modelo \n",
    "    kde = KernelDensity(kernel=k).fit(x_orig) # usamos el punto (0,0)\n",
    "    # log de la densidad de probabilidad (PDF)\n",
    "    log_dens = kde.score_samples(x_plot) \n",
    "    \n",
    "    # Graficar la estimacion para cada kernel\n",
    "    plt.plot(x_plot[:,0], np.exp(log_dens), label=f'{k.capitalize()} Kernel')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Estimaci√≥n con diferentes Kernels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veamos qu√© ocurre si para un mismo kernel, cambiamos los **anchos de banda**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anchos de banda\n",
    "bandwidths = [0.5, 0.75, 1, 1.25, 1.5, 1.75] \n",
    "  \n",
    "# Figura con 3 filas y 2 columnas\n",
    "fig, ax = plt.subplots(3, 2) \n",
    "# Tama√±o de la figura\n",
    "fig.set_figheight(15) \n",
    "fig.set_figwidth(10)   \n",
    "# T√≠tulo \n",
    "fig.suptitle('Kernel Gaussiano, con distintos anchos de banda')\n",
    "\n",
    "# Graficamos usando los distintos kernels \n",
    "for i, bw in enumerate(bandwidths): \n",
    "    # Ajustamos el modelo \n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=bw).fit(x_orig) # usamos el punto (0,0)\n",
    "    # log de la densidad de probabilidad (PDF)\n",
    "    log_dens = kde.score_samples(x_plot) \n",
    "      \n",
    "    # Distribuciones \n",
    "    ax[i // 2, i % 2].fill(x_plot[:, 0], np.exp(log_dens)) \n",
    "    # i//2 nos permite referirnos a la fila del subplot, e i%2 nos permite referirnos a la columna\n",
    "    # T√≠tulo y labels de los subplots \n",
    "    ax[i // 2, i % 2].set_title('Kernel Gaussiano con bandwidth='+str(bw)) \n",
    "    ax[i // 2, i % 2].set_xlim(-3, 3) \n",
    "    ax[i // 2, i % 2].set_ylim(0, 1) \n",
    "    ax[i // 2, i % 2].set_ylabel('Densidad') \n",
    "    ax[i // 2, i % 2].set_xlabel('x') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anchos de banda\n",
    "bandwidths = [0.5, 0.75, 1, 1.25, 1.5, 1.75] \n",
    "  \n",
    "# Grafico\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "for bw in bandwidths:\n",
    "    # Ajustamos el modelo \n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=bw).fit(x_orig) # usamos el punto (0,0)\n",
    "    # log de la densidad de probabilidad (PDF)\n",
    "    log_dens = kde.score_samples(x_plot) \n",
    "    \n",
    "    # Graficar la estimacion para cada kernel\n",
    "    plt.plot(x_plot[:,0], np.exp(log_dens), label='Kernel Gaussiano con bandwidth='+str(bw))\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Kernel Gaussiano, con distintos anchos de banda') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veamos un ejemplo con datos ficticios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una distribuci√≥n\n",
    "n = 100\n",
    "np.random.seed(10)\n",
    "X = np.concatenate((np.random.normal(0, 1, int(0.6 * n)), np.random.normal(10, 1, int(0.4 * n)))) \n",
    "# Creamos X concatenando datos de dos distribuciones normales\n",
    "# primero 60 datos de una distribuci√≥n normal con media 0 y desv√≠o 1\n",
    "# luego, 40 datos de una normal con media 10 y desv√≠o 1\n",
    "X = X.reshape(-1,1)\n",
    "\n",
    "X_plot = np.linspace(-5, 15, 1000).reshape(-1,1)\n",
    "# Usaremos X para estimar la densidad y calcularemos la densidad para los puntos de X_plot \n",
    "\n",
    "# Calcular la \"verdera\" densidad para los puntos X_plot\n",
    "true_density = 0.6 * norm(0, 1).pdf(X_plot[:, 0]) + 0.4 * norm(10, 1).pdf(X_plot[:, 0]) \n",
    "  \n",
    "# Gr√°fico\n",
    "fig, ax = plt.subplots() \n",
    "  \n",
    "# Gr√°fico de la verdadera densidad \n",
    "ax.fill( \n",
    "    X_plot[:, 0], true_density,  \n",
    "    fc='black', alpha=0.2,  \n",
    "    label='Distribuci√≥n'\n",
    ") \n",
    "  \n",
    "# Estimar la densidad de X usando kernel gaussiano y bandwidth de 0.5 \n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.5).fit(X) \n",
    "# Log de la PDF \n",
    "log_dens = kde.score_samples(X_plot) \n",
    "  \n",
    "# Densidad \n",
    "ax.plot( \n",
    "    X_plot[:, 0], np.exp(log_dens), \n",
    "    color='blue', \n",
    "    linestyle='-', \n",
    "    label='Densidad con kernel Gaussiano'\n",
    ")  \n",
    "ax.set_xlim(-4, 15) \n",
    "ax.set_ylim(0, 0.3) \n",
    "#ax.grid(True) \n",
    "ax.legend(loc='upper right') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro ejemplo probando kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos datos\n",
    "np.random.seed(20)\n",
    "X = np.concatenate([np.random.normal(0,1,500), np.random.normal(5,1,500)]).reshape(-1,1)\n",
    "X\n",
    "\n",
    "# Rango de valores para eje x\n",
    "X_plot = np.linspace(min(X), max(X), 1000).reshape(-1,1)\n",
    "#X_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de kernels a probar\n",
    "kernels = [\"gaussian\", \"tophat\", \"epanechnikov\", \"exponential\", \"linear\", \"cosine\"] \n",
    "\n",
    "# Grafico\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(X, bins=30, density=True, alpha=0.5, color='blue', label='Histograma')\n",
    "\n",
    "for k in kernels:\n",
    "    kde = KernelDensity(kernel=k).fit(X)\n",
    "    \n",
    "    # Usar la KDE para estimar la densidad para cada valor de X\n",
    "    log_densities = kde.score_samples(X_plot)\n",
    "    densities = np.exp(log_densities)\n",
    "    \n",
    "    # Graficar para cada kernel\n",
    "    plt.plot(X_plot[:,0], densities, label=f'{k.capitalize()} Kernel')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Estimaci√≥n con diferentes Kernels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para elegir el bandwidth con CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Grilla de posibles anchos de banda\n",
    "bandwidths = 10 ** np.linspace(-1, 1, 10)\n",
    "print(bandwidths)\n",
    "\n",
    "# Datos con los que se estima KDE\n",
    "np.random.seed(20)\n",
    "X = np.concatenate([np.random.normal(0,1,50), np.random.normal(5,1,50)]).reshape(-1,1)\n",
    "X\n",
    "\n",
    "grid = GridSearchCV(KernelDensity(kernel='gaussian'),\n",
    "                    {'bandwidth': bandwidths},\n",
    "                    cv=5)\n",
    "grid.fit(X)\n",
    "grid.best_params_ #mejor ancho de banda (de los posibles dentro de la grilla)\n",
    "best_bw = grid.best_params_['bandwidth']\n",
    "best_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repito lo mismo con el bandwidth √≥ptimo\n",
    "\n",
    "# Lista de kernels a probar\n",
    "kernels = [\"gaussian\", \"tophat\", \"epanechnikov\", \"exponential\", \"linear\", \"cosine\"] \n",
    "\n",
    "# Grafico\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(X, bins=30, density=True, alpha=0.5, color='blue', label='Histograma')\n",
    "\n",
    "for k in kernels:\n",
    "    kde = KernelDensity(kernel=k, bandwidth = best_bw).fit(X)\n",
    "    \n",
    "    # Usar la KDE para estimar la densidad para cada valor de X\n",
    "    log_densities = kde.score_samples(X_plot)\n",
    "    densities = np.exp(log_densities)\n",
    "    \n",
    "    # Graficar para cada kernel\n",
    "    plt.plot(X_plot[:,0], densities, label=f'{k.capitalize()} Kernel')\n",
    "\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.title('Estimaci√≥n con diferentes Kernels')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
